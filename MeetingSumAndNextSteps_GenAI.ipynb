{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Vertex AI SDK initialize Vertex AI** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform --upgrade --user\r\n",
    "\r\n",
    "PROJECT_ID = \"#GCP-project-id\" #given by GCP\r\n",
    "LOCATION = \"us-central1\" #your local area\r\n",
    "\r\n",
    "import vertexai\r\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "Prompt should include the task, examples of input with correct-outputs, the new input, and the result unduction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetingtext = \"\"\"\n",
    "AI governance team. Responsible AI.\n",
    "* Everyone is an AI user and responsible for this. How to make everyone a part of this.\n",
    "* cloud governance at wells fargo. 13 years at cisco previously. Cloud operations team and evolved into cloud governance. Shifting into risk management space. Finishing at Cal and has a final project. Continuous modernization of tech with cloud. Ai governance office in coming months.\n",
    "* Top of mind\n",
    "** Risk aversion and how to mitigate risk\n",
    "** Want to understand the reality of it\n",
    "** Refuse to gamble on this since we’re regulated\n",
    "*** E.g. Palantir. Was a no and not a conversation piece. Use some of their tech but not all their sensitive information. Damage would be too significant.\n",
    "* Risk management categories\n",
    "** Data quality. Data is super important to them. Old company and gaps in old data. Some parts of the business are more advanced than others.\n",
    "** Some groups we can charge ahead on and others they can move out of the stone age. Don’t trust the data. Has to be proven out and not just that but a soak in period. Slow to put into production at times. Quality data or just crap.\n",
    "**  Super slow to move to cloud. Even though there’s agreements and legal is taken care of, there’s minimal trust that data wouldn’t be breached.\n",
    "** Spent 30 years being risk adverse\n",
    "* Teams trying to mitigate risk of AI but also push and use AI to mitigate business risk. There are teams out there on the cutting edge.\n",
    "** But still, we rely on human decision for the final operational decision.\n",
    "* Have a lot of guys in the military that we put in operational roles that are used to risk aversion. Deliberate actions and no guessing. How does AI fit into that spot?\n",
    "* Human systems are biased just like AI systems are but you can only measure one well and not the other. How do you approach that evaluation of systems?\n",
    "* In the same way where they hire consulting firms based on reputation, they want to bring in AI in the same way, but this doesn’t exist.\n",
    "* “we used to be that way with cloud”\n",
    "** In a similar way, AI is on the same path. There was a lot of FUD associated with the risks here and not well understood. It takes time to build that trust.\n",
    "* International regulation is SUPER important and there’s so many grey areas.\n",
    "* When you think about regulation and privacy, I think about international regulation.\n",
    "* Struggling that everyone knows what they’re talking about\n",
    "* How are you educating?\n",
    "** How to educate peers on how other people outside their world are thinking about and looking at this\n",
    "* How are you serving your customers and your RESPONSIBILITY to them\n",
    "* WE focus on regulators more than we focus on the customers sometimes\n",
    "* There’s so many opportunities in leveraging AI\n",
    "** Utilize to improve efficiency in business processes\n",
    "** Relying on it for decision making. Rules and language models\n",
    "* Poisoning of training scares me the most.\n",
    "* LLMs will be another utility just like power, just like cloud, and now LLMs because you need the scale\n",
    "* Concerned of 3rd party and SaaS\n",
    "** 2 parts of that fear\n",
    "** 1 using anything that’s abstracted 3rd party abstraction\n",
    "*** You are responsible and liable. Shared responsibility model is a joke\n",
    "*** Ultimately the customer of the shared service is liable\n",
    "*** How to establish liability is complicated\n",
    "** 2 threat model in the space of attacks\n",
    "*** Can be there just for using systems and having them a part of your systems\n",
    "*** When you come to things like co-creation there are multiple avenues to come to that model\n",
    "*** Need to share that inputs\n",
    "* Opportunity from the user based whether they mean it or not. Coud. Be fat fingers.\n",
    "* How to balance innovation from the risks we’re talking about\n",
    "* How to take an abstract system and how do you trust it to make life or death decisions?\n",
    "* You’re taking a probabilistic system that’s making life/death decisions, you better have a human in there just like you’d have multiple humans to decide what to do. There should be redundancies in the important decisions. Decisions validated by the human.\n",
    "** What’s the inflection point where you begin to trust it?\n",
    "* Longs ways out from operational decisions in real-time\n",
    "* Regulators haven’t come out with definitive guidance yet.\n",
    "* 3 lines of defense\n",
    "** Business\n",
    "** Measure, monitor, report, mitigate, control\n",
    "** Internal/external auditors\n",
    "* Question to the board: you know we use AI in our underwriting, right? Yes. What else do you know? … crickets\n",
    "* Underwriting and fraud is the top AI use case\n",
    "* OCC mission statement: fairness fairness fairness\n",
    "* Have all sorts of models\n",
    "** Linear regression you can EXPLAIN why you did or didn’t get a loan\n",
    "** On the other side, you can’t explain… OCC is concerned\n",
    "* How do you explain WHY you didn’t get a loan?\n",
    "* Explainable AI NEEDS to exist so that we can use these things\n",
    "* Shapley value. Average contribution of a variable to the overall outcome\n",
    "* Modern AI systems cannot comply with 1 line of GDPR\n",
    "** What line? Didn’t hear which\n",
    "* Inaction doesn’t introduce me to risk but action does introduce me to risk if I implement\n",
    "* I’m not responsible for the inequality of society baked into these models\n",
    "* If you want to make a fair system, you might need to collect demographic data\n",
    "** But you might not be able to collect that data due to GDPR and other privacy rules\n",
    "** But then you can’t use the models because you’re at risk of the inherent bias already baked in,\n",
    "** Lose both ways\n",
    "* 3rd party risk management\n",
    "** Didn’t engage them, I engaged you. You have to be ahead of this and you’re responsible.\n",
    "* Government can’t keep up with tech progress\n",
    "* Supply chain of governance with private companies also in the loop while we wait for government to provide regulation\n",
    "* Private sector has 1000 AI engineers. Gov has 10. YOU write these up and send them to us. Start to make progress and write up what you think it should be\n",
    "* Trading risk for cost\n",
    "** Human in the loop\n",
    "** Explainability sake – surrogate models. 2nd model is able to explain the decision the 1st model made. Surrogate model has to be in the works for a while. This is what can be taken to the regulatory agencies.\n",
    "* Banks hate human in the loop\n",
    "** Because you go from objective to subjective. Especially with linear regression.\n",
    "** Subjective nature of the model but ALSO now I have to explain the human in the loop. Theres 2 modes of failure here\n",
    "* What’s the inflection point where model confidence is a subjective decision for humans? E.g. 99.9% confidence then you have a rubber stamp. 80%? Other?\n",
    "* Self driving cars are good example\n",
    "* Both machines make mistakes and humans make mistakes.\n",
    "** We want AI to make the same mistakes as humans make\n",
    "** But still, humans are at fault\n",
    "* Is there a liability in the same way that self driving cars are? L1-5 where liability goes from the human in the loop to the manufacturer?\n",
    "* Move to AI hasn’t been about improving performance as it is improving cost structures today\n",
    "* There’s a lot of costs associated with human to human. Typically not lossless. But working with AI systems it’s much more lossless.\n",
    "* The risk/cost problem is strongly coorelated to the human/machine quality tradeoff.\n",
    "* What are the use cases you can apply these\n",
    "* How do you bare out the risk in financial terms?\n",
    "* What are the industries that do allow for efficiencies?\n",
    "* There’s a time horizon on risk\n",
    "** E.g. there are some decisions that you see the immediate yes/no or true/false. Others like 30 year mortgage you may not know until 12-15 years later. Risk is different\n",
    "* You’re adding risk to particular use cases. You first go to non-regulated places.\n",
    "* AI is in the unknown unknown risk bucket.\n",
    "* Near term goal is to analogize and tell stories\n",
    "* Need a lingua franca to be able to talk about AI across many different stakeholder groups\n",
    "* How do we get people from starting off to freshman team to the JV team in various topics?\n",
    "* GenAI risk is you’re using data that doesn’t belong to you\n",
    "** Have been trained on not your data and unrelated to you\n",
    "* Always more better data and a simple model than crappier data and a better model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_line = '\\n'\n",
    "\n",
    "prompt_text = f\"\"\"Text:{meetingtext}\"\"\"\n",
    "# print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_task = \"\"\"Summarize the meeting according to the following text.\"\"\" #summary task\n",
    "concern_task = \"\"\"Give 5 top concerns that come out from this conversation.\"\"\" #concerns task\n",
    "positive_task = \"\"\"Give 5 top positive feedbacks that come out from this conversation.\"\"\" #positive task\n",
    "recommend_task = \"\"\"Give 5 recommendations on what to focus on from this conversation.\"\"\" #recommendations task\n",
    "meeting_task_list = [summarize_task, concern_task, positive_task, recommend_task]\n",
    "# print(meeting_task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_init = \"\"\"Summarization:\"\"\" #initialize summary task\n",
    "concern_init = \"\"\"Concenrns:\"\"\" #initialize concenrs task\n",
    "positive_init = \"\"\"Positive feedback:\"\"\" #initialize positive feedback task\n",
    "recommend_init = \"\"\"Recommendations:\"\"\" #initialize recommendation task\n",
    "meeting_init_list = [summarize_init, concern_init, positive_init, recommend_init]\n",
    "# print(meeting_init_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_prompt = f\"\"\"{summarize_task}{prompt_text}{summarize_init}\"\"\"\n",
    "# concern_prompt = f\"\"\"{concern_task}{prompt_text}{concern_init}\"\"\"\n",
    "# positive_prompt = f\"\"\"{positive_task}{prompt_text}{positive_init}\"\"\"\n",
    "# recommend_prompt = f\"\"\"{recommend_task}{prompt_text}{recommend_init}\"\"\"\n",
    "# meeting_prompts = [summarize_prompt, concern_prompt, positive_prompt, recommend_prompt]\n",
    "# #print(meeting_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dictionaries with tople "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "length = len(meeting_task_list)\n",
    "prompt_list = []\n",
    "for i in range(length):\n",
    "    task = meeting_task_list[i]\n",
    "    init = meeting_init_list[i]\n",
    "    prompt = f\"\"\"{task}{new_line}{prompt_text}{init}\"\"\"\n",
    "    # print(i, \"; \", f\"\"\"{task}{new_line}{prompt_text}{init}\"\"\")\n",
    "    prompt_list.insert(i, prompt)\n",
    "# print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_summarize = generation_model.predict(\n",
    "#         meeting_prompts[0], temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "#     ).text\n",
    "# result_concern = generation_model.predict(\n",
    "#         meeting_prompts[1], temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "#     ).text\n",
    "# result_positive = generation_model.predict(\n",
    "#         meeting_prompts[2], temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "#     ).text\n",
    "# result_recommend = generation_model.predict(\n",
    "#         meeting_prompts[3], temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "#     ).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for i in range(length):\n",
    "    result = generation_model.predict(\n",
    "        prompt_list[i], temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text    \n",
    "    # print(i, \"; \", result)\n",
    "    result_list.insert(i, result) # change to .append\n",
    "print(result_list[0])\n",
    "######## was not checked ###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the task type and results from the same task type in one list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meeting_result_summarize = f\"\"\"{meeting_init_list[0]}{new_line}{result_summarize}\"\"\"\r\n",
    "\r\n",
    "print_result_list = []\r\n",
    "for i in range(length):\r\n",
    "    printresult = f\"{meeting_init_list[i]}{new_line}{result_list[i]}{new_line}\" # \\\\n should be a new line in f\r\n",
    "    # print(i, \"; \", printresult)\r\n",
    "    print_result_list.insert(i, printresult) # change to .append\r\n",
    "print(print_result_list[0])\r\n",
    "\r\n",
    "######## was not checked ###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the execution result of the meeting in a summarization manner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The summerization of this meeting is the following:{new_line}{print_result_list[0], {new_line}{print_result_list[1]}, {new_line}{print_result_list[3]\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33ac2f6c3d6adfd68087f6d15ad3db9c1b2bf5218b95d3579f23e5deb638db1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}