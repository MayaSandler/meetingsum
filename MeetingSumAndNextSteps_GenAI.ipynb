{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Vertex AI SDK initialize Vertex AI** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_to_use = ['Summary', 'Concenrns', 'Recommendations'] #change according to need #'positives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_ID = \"#GCP-project-id\" #needs to change according to your GCP ID\n",
    "# LOCATION = \"#your local area\" #needs to change according to your GCP location\n",
    "\n",
    "# import vertexai\n",
    "# vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "Prompt should include the task, examples of input with correct-outputs, the new input, and the result unduction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace meeting text with your data\n",
    "meetingtext = \"\"\"meeting text \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \" Text: \" + meetingtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': ['Summarize the meeting in one to five sentences according to the following text.', 'Summary:'], 'Concenrns': ['Give 5 top concerns that come out from this conversation.', 'Concerns:'], 'Positives': ['Give 5 top positive feedbacks that come out from this conversation.', 'Positive feedback:'], 'Recommendations': ['Give 5 recommendations on what to focus on from this conversation.', 'Recommendations:']}\n"
     ]
    }
   ],
   "source": [
    "prompt_dict = {\n",
    "        'Summary' : ['Summarize the meeting in one to five sentences according to the following text.', 'Summary:'] #summary task\n",
    "        , 'Concenrns' : ['Give 5 top concerns that come out from this conversation.', 'Concerns:'] #concenrns task\n",
    "        , 'Positives' : ['Give 5 top positive feedbacks that come out from this conversation.', 'Positive feedback:'] #positive task\n",
    "        , 'Recommendations' : ['Give 5 recommendations on what to focus on from this conversation.', 'Recommendations:'] #recommendations task\n",
    "}\n",
    "print(prompt_dict)\n",
    "# print(prompt_dict['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the meeting in one to five sentences according to the following text. Text: meeting text \n",
      "Summary:\n",
      "Give 5 top concerns that come out from this conversation. Text: meeting text \n",
      "Concerns:\n",
      "Give 5 recommendations on what to focus on from this conversation. Text: meeting text \n",
      "Recommendations:\n"
     ]
    }
   ],
   "source": [
    "for k, v in prompt_dict.items():\n",
    "    # print(k, \"; \", v)\n",
    "    if k in prompts_to_use: \n",
    "        # print('I am in!')\n",
    "        # print(k)\n",
    "        # print(v[0])\n",
    "        prompt = prompt_dict[k][0] + prompt_text + prompt_dict[k][1]\n",
    "        # print(prompt)\n",
    "        prompt_dict[k].append(prompt)\n",
    "        # print(prompt_dict[k][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in prompt_dict.items():\n",
    "    # print(k, \"; \", v)\n",
    "    if k in prompts_to_use: #execute prediction\n",
    "        # pass\n",
    "        # print(k) #print the key\n",
    "        # print(prompt_dict[k][0])    #print the value \n",
    "        \n",
    "        result = generation_model.predict(\n",
    "            prompt_dict[k][2], temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "        ).text    \n",
    "        prompt_dict[k].append(result)\n",
    "        print(prompt_dict[k][3]) #the result of the prediction model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in prompt_dict.items():\n",
    "    # print(k, \"; \", v)\n",
    "    if k in prompts_to_use: #execute prediction\n",
    "        print(f\"{k} \\n{prompt_dict[k][3]}\\n\") #print the type of prediction and the resul"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33ac2f6c3d6adfd68087f6d15ad3db9c1b2bf5218b95d3579f23e5deb638db1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
